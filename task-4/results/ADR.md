### **Название задачи:**

Реализация ETL с использованием Spring Batch для обработки складских отчётов TradeWare

### **Автор:**

Минлигареев Максим

### **Дата:**

25.12.2025

---

## **Функциональные требования**

| **№** | **Действующие лица или системы**          | **Use Case**                         | **Описание**                                                                                                                                                                                                                                 |
| :---: | :---------------------------------------- | :----------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
|   1   | Сотрудник склада, ERP Web UI              | Загрузка отчёта                      | 1) Сотрудник формирует отчёт в Excel по шаблону и сохраняет в CSV. 2) Загружает CSV через UI. 3) UI отправляет файл в Backend API.                                                                                                           |
|   2   | Backend API (монолит/WildFly), GCS        | Приём файла и сохранение в хранилище | 1) Backend валидирует базовый формат файла. 2) Сохраняет файл в объектное хранилище (GCS). 3) Создаёт запись о загрузке (job) со статусом `queued/accepted`.                                                                                 |
|   3   | Spring Batch ETL Service, PostgreSQL, GCS | ETL-обработка отчёта (batch)         | 1) ETL сервис получает путь к файлу (из БД/очереди). 2) Читает CSV (chunk processing). 3) Обогащает данные справочниками из PostgreSQL (например, loyality_data). 4) Записывает результат в целевые таблицы PostgreSQL (bulk insert/upsert). |
|   4   | Backend API, ERP Web UI                   | Получение статуса обработки          | 1) UI запрашивает статус job. 2) Backend возвращает статус (`processing/success/failed`) и сообщение об ошибке (если есть).                                                                                                                  |
|   5   | Сотрудник склада                          | Повторная загрузка при ошибке        | 1) При ошибке формата/обработки сотрудник исправляет CSV. 2) Загружает повторно. 3) Создаётся новый job, прошлый остаётся в истории.                                                                                                         |

> POC из задания покрывает частный случай: загрузка `product-data.csv`, enrichment из таблицы `loyality_data`, запись в таблицу `products` в PostgreSQL.

---

## **Нефункциональные требования**

| **№** | **Требование**                                                                                                                                               |
| :---: | :----------------------------------------------------------------------------------------------------------------------------------------------------------- |
|   1   | Масштабирование под нагрузкой: способность принять 100–150 параллельных загрузок в пиковые часы без блокирования онлайн-компонентов (асинхронная обработка). |
|   2   | Производительность: среднее время обработки отчёта на 2000 строк — до 30 секунд (ориентир).                                                                  |
|   3   | Пакетная обработка вместо построчных транзакций: минимизация lock contention и нагрузки на PostgreSQL (bulk операции).                                       |
|   4   | Надёжность: retry/повторяемость обработки, идемпотентность при повторной обработке файла (например, через staging + upsert + jobId).                         |
|   5   | Наблюдаемость: централизованные логи и метрики (Prometheus/Grafana + ELK), корреляция по jobId.                                                              |
|   6   | Совместимость со стеком и миграцией: решение должно хорошо интегрироваться с Java-экосистемой и позволять постепенный вынос из монолита в микросервисы.      |
|   7   | Эксплуатация в облаке: развёртывание контейнеров в k8s (GCP), конфигурация через env/secrets, возможность горизонтального масштабирования воркеров.          |

---

## **Решение**

### C4 (Context / Container)

- Контекстная и контейнерная диаграммы находятся в файле `c4-to-be.puml` (в директории Task4/results).
- В решении присутствуют компоненты:
  - **ERP Web UI (Angular)** — загрузка CSV и просмотр статуса.
  - **Backend API (WildFly/Java)** — приём файла, базовая валидация, запись метаданных о job.
  - **GCS (Object Storage)** — хранение исходных отчётов.
  - **PostgreSQL** — справочники/номенклатура/таблицы batch, таблицы статусов job.
  - **Spring Batch ETL Service** — пакетная обработка CSV (chunk), enrichment из БД, запись результата (bulk).
  - **Observability Stack** — метрики/логи/трейсы.

### Логика выбора Spring Batch

- В компании уже есть Java-стек и опыт команды со Spring Batch → снижает time-to-market и риски внедрения.
- Spring Batch нативно решает типовые ETL-задачи: chunk processing, транзакционность, listeners, обработку ошибок.
- Вынесение тяжёлой обработки из “онлайна” в отдельный batch-компонент разгружает API и повышает стабильность в пике.
- Архитектурно это промежуточный шаг к микросервисам: ETL сервис можно независимо разворачивать и масштабировать.

### POC (что продемонстрировано)

Локально развернули PostgreSQL и Spring Batch приложение через docker-compose.
POC выполняет ETL шаг:

- читает `product-data.csv`,
- обогащает записи данными из таблицы `loyality_data`,
- записывает результат в `products`,
- выводит логи “Transforming…” и “JOB FINISHED…”, а также позволяет показать содержимое таблицы `products`.

---

## **Альтернативы**

1. **Apache Airflow**

- Плюсы: оркестрация пайплайнов, UI, история запусков, сенсоры, готовые интеграции.
- Минусы: более тяжёлая инфраструктура (scheduler/webserver/metadata DB), для ETL на Java может быть избыточен.

2. **Kubernetes CronJob + самописный обработчик**

- Плюсы: очень простое расписание, минимум компонентов.
- Минусы: при росте требований (история запусков, retries, ветвления, аудит, SLA) быстро усложняется и превращается в “самодельный оркестратор”.

3. **Spark / managed data processing (Dataproc/Dataflow)**

- Плюсы: подходит для очень больших объёмов и сложных трансформаций.
- Минусы: сложнее эксплуатация и стоимость; для текущей задачи может быть преждевременно.

---

## **Недостатки, ограничения, риски**

- **Риск блокировок и нагрузки на PostgreSQL**, если писать построчно → требуется bulk insert/upsert, staging и грамотные индексы.
- **Идемпотентность**: при повторном запуске одного файла нельзя дублировать данные → нужен jobId, контроль повторной обработки, staging + merge/upsert.
- **Рост параллелизма**: при 100–150 загрузках нужна очередь (Kafka/PubSub) и масштабирование воркеров; иначе монолит будет “пытаться обработать всё сразу”.
- **Оперирование batch-инфраструктурой**: нужно хранить историю запусков, статусы, причины ошибок (job repository + таблица job_runs).
- **Наблюдаемость**: если не внедрить метрики/логи/корреляцию по jobId, диагностика в пике будет сложной.
- **Зависимость от Java-экосистемы**: Spring Batch хорош для Java, но может усложнить подключение команд/сервисов вне JVM.
